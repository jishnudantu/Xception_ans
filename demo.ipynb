{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model(dropout_rate, model_weights_filename):\n",
    "    print(\"Creating Model...\")\n",
    "    metadata = get_metadata()\n",
    "    num_classes = len(metadata['ix_to_ans'].keys())+1\n",
    "    num_words = len(metadata['ix_to_word'].keys())\n",
    "\n",
    "    embedding_matrix = prepare_embeddings(num_words, embedding_dim, metadata)\n",
    "    model = vqa_model(embedding_matrix, num_words, embedding_dim, seq_length, dropout_rate, num_classes)\n",
    "    if os.path.exists(model_weights_filename):\n",
    "        print(\"Loading Weights...\")\n",
    "        model.load_weights(model_weights_filename)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model...\n",
      "Creating image model...\n",
      "Creating text model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data_processed/models.py:11: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(trainable=True, units=512, return_sequences=True, input_shape=(26, 300))`\n",
      "  model.add(LSTM(output_dim=512, return_sequences=True, input_shape=(seq_length, embedding_dim),trainable=True))\n",
      "/home/ubuntu/data_processed/models.py:13: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(trainable=True, units=512, return_sequences=False)`\n",
      "  model.add(LSTM(output_dim=512, return_sequences=False,trainable=True))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging final model...\n",
      "Loading Weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data_processed/models.py:29: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  fc_model.add(Merge([vgg_model, lstm_model], mode='mul'))\n"
     ]
    }
   ],
   "source": [
    "model = get_model(0.0,'/home/ubuntu/data_processed/data/model_weights_xception.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_vqa.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import json\n",
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_img = '/home/ubuntu/data/data_processed/data_img.h5'\n",
    "data_prepo = '/home/ubuntu/data/data_processed/data_prepro.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def right_align(seq,lengths):\n",
    "    v = np.zeros(np.shape(seq))\n",
    "    N = np.shape(seq)[1]\n",
    "    for i in range(np.shape(seq)[0]):\n",
    "        v[i][N-lengths[i]:N]=seq[i][0:lengths[i]]\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_val_data_final():\n",
    "    img_data = h5py.File(data_img)\n",
    "    ques_data = h5py.File(data_prepo)\n",
    "\n",
    "    img_data = np.array(img_data['images_test'])\n",
    "    img_pos_train = ques_data['img_pos_test']\n",
    "    train_img_data = np.array([img_data[_-1,:] for _ in img_pos_train])\n",
    "    tem = np.sqrt(np.sum(np.multiply(train_img_data, train_img_data), axis=1))\n",
    "    train_img_data = np.divide(train_img_data, np.transpose(np.tile(tem,(2048,1))))\n",
    "\n",
    "    ques_train = np.array(ques_data['ques_test'])\n",
    "    ques_length_train = np.array(ques_data['ques_length_test'])\n",
    "    ques_train = right_align(ques_train, ques_length_train)\n",
    "\n",
    "    # Convert all last index to 0, coz embeddings were made that way :/\n",
    "    for _ in ques_train:\n",
    "        if 12602 in _:\n",
    "            _[_==12602] = 0\n",
    "\n",
    "    val_X = [train_img_data, ques_train]\n",
    "\n",
    "    return val_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_X = get_val_data_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  1.17133798e-03,   2.93803322e-05,   0.00000000e+00, ...,\n",
       "           3.06069292e-02,   1.02472061e-02,   2.67547224e-02],\n",
       "        [  1.17133798e-03,   2.93803322e-05,   0.00000000e+00, ...,\n",
       "           3.06069292e-02,   1.02472061e-02,   2.67547224e-02],\n",
       "        [  1.17133798e-03,   2.93803322e-05,   0.00000000e+00, ...,\n",
       "           3.06069292e-02,   1.02472061e-02,   2.67547224e-02],\n",
       "        ..., \n",
       "        [  5.16341685e-02,   2.03264328e-03,   1.87685913e-02, ...,\n",
       "           5.75522990e-02,   0.00000000e+00,   3.20554095e-03],\n",
       "        [  5.16341685e-02,   2.03264328e-03,   1.87685913e-02, ...,\n",
       "           5.75522990e-02,   0.00000000e+00,   3.20554095e-03],\n",
       "        [  5.16341685e-02,   2.03264328e-03,   1.87685913e-02, ...,\n",
       "           5.75522990e-02,   0.00000000e+00,   3.20554095e-03]]),\n",
       " array([[     0.,      0.,      0., ...,   8627.,   7126.,   4726.],\n",
       "        [     0.,      0.,      0., ...,   7549.,   7969.,   4726.],\n",
       "        [     0.,      0.,      0., ...,  12516.,   1873.,   4726.],\n",
       "        ..., \n",
       "        [     0.,      0.,      0., ...,  13499.,    931.,   4726.],\n",
       "        [     0.,      0.,      0., ...,  13499.,   3512.,   4726.],\n",
       "        [     0.,      0.,      0., ...,   9744.,  11808.,   4726.]])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dtype=\"float32\", batch_input_shape=[None, 204..., activity_regularizer=None, activation=\"tanh\", kernel_initializer=\"glorot_uniform\", use_bias=True, bias_constraint=None, bias_regularizer=None, kernel_constraint=None, kernel_regularizer=None, trainable=True, units=1024, name=\"dense_1\", input_dim=4096)`\n",
      "  return cls(**config)\n",
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py:1252: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "  return cls(**config)\n",
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(input_dtype=\"float32\", batch_input_shape=[None, 26], input_dim=14771, embeddings_initializer=\"uniform\", output_dim=300, embeddings_constraint=None, mask_zero=False, input_length=26, trainable=False, name=\"embedding_1\", embeddings_regularizer=None, activity_regularizer=None)`\n",
      "  return cls(**config)\n",
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py:1252: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  return cls(**config)\n",
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(stateful=False, input_shape=(None, 300..., batch_input_shape=[None, 26,..., return_sequences=True, units=512, bias_regularizer=None, dropout=0.0, recurrent_initializer=\"orthogonal\", name=\"lstm_1\", recurrent_regularizer=None, kernel_regularizer=None, go_backwards=False, unit_forget_bias=True, input_dtype=\"float32\", recurrent_activation=\"hard_sigmoid\", implementation=0, activation=\"tanh\", kernel_initializer=\"glorot_uniform\", unroll=False, trainable=True, recurrent_dropout=0.0)`\n",
      "  return cls(**config)\n",
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(name=\"dropout_1\", rate=0.0, trainable=True)`\n",
      "  return cls(**config)\n",
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(stateful=False, input_shape=(None, 512..., go_backwards=False, return_sequences=False, units=512, bias_regularizer=None, dropout=0.0, recurrent_initializer=\"orthogonal\", name=\"lstm_2\", recurrent_regularizer=None, kernel_regularizer=None, unit_forget_bias=True, recurrent_activation=\"hard_sigmoid\", implementation=0, activation=\"tanh\", kernel_initializer=\"glorot_uniform\", unroll=False, trainable=True, recurrent_dropout=0.0)`\n",
      "  return cls(**config)\n",
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(name=\"dropout_2\", rate=0.0, trainable=True)`\n",
      "  return cls(**config)\n",
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=None, activity_regularizer=None, activation=\"tanh\", kernel_initializer=\"glorot_uniform\", use_bias=True, units=1024, bias_regularizer=None, bias_constraint=None, trainable=True, name=\"dense_2\", kernel_regularizer=None, kernel_constraint=None)`\n",
      "  return cls(**config)\n",
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py:1252: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n",
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(name=\"dropout_3\", rate=0.0, trainable=True)`\n",
      "  return cls(**config)\n",
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=None, activity_regularizer=None, activation=\"tanh\", kernel_initializer=\"glorot_uniform\", use_bias=True, units=1000, bias_regularizer=None, bias_constraint=None, trainable=True, name=\"dense_3\", kernel_regularizer=None, kernel_constraint=None)`\n",
      "  return cls(**config)\n",
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(name=\"dropout_4\", rate=0.0, trainable=True)`\n",
      "  return cls(**config)\n",
      "/home/ubuntu/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=None, activity_regularizer=None, activation=\"softmax\", kernel_initializer=\"glorot_uniform\", use_bias=True, units=1001, bias_regularizer=None, bias_constraint=None, trainable=True, name=\"dense_4\", kernel_regularizer=None, kernel_constraint=None)`\n",
      "  return cls(**config)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.tokenize import word_tokenize\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "model_filename = '/home/ubuntu/app/resources/model.json'\n",
    "model_weights_filename = '/home/ubuntu/app/resources/model_weights_xception.h5'\n",
    "json_file = open(model_filename, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "# print \"Reading Model...\"\n",
    "model = model_from_json(loaded_model_json)\n",
    "# print \"Loading Weights...\"\n",
    "model.load_weights(model_weights_filename)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "metadata = json.load(open('/home/ubuntu/app/resources/data_prepro.json', 'r'))\n",
    "metadata['ix_to_word'] = {str(word):int(i) for i,word in metadata['ix_to_word'].items()}\n",
    "\n",
    "def get_ques_vector(question):\n",
    "    question_vector = []\n",
    "    seq_length = 26\n",
    "    word_index = metadata['ix_to_word']\n",
    "    for word in word_tokenize(question.lower()):\n",
    "        if word in word_index:\n",
    "            question_vector.append(word_index[word])\n",
    "        else:\n",
    "            question_vector.append(0)\n",
    "    question_vector = np.array(pad_sequences([question_vector], maxlen=seq_length))[0]\n",
    "    question_vector = question_vector.reshape((1,seq_length))\n",
    "    return question_vector\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = h5py.File('/home/ubuntu/app/data_img.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['images_train'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "image_id = '1'\n",
    "\n",
    "img_vector = img_data['images_test'][int(image_id)]\n",
    "img_vector = img_vector.reshape((1,2048))\n",
    "question_vector = get_ques_vector('what is the color?')\n",
    "pred = model.predict([img_vector, question_vector])[0]\n",
    "top_pred = pred.argsort()[-5:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  5,  7, 26, 13])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Black', 82.719999999999999),\n",
       " ('White', 3.8300000000000001),\n",
       " ('Red', 2.1400000000000001),\n",
       " ('Gray', 2.04),\n",
       " ('Brown', 1.99)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(metadata['ix_to_ans'][str(_)].title(), round(pred[_]*100.0,2)) for _ in top_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import h5py\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from skimage import io\n",
    " \n",
    "\n",
    "def image_preprocess(url):\n",
    "    image = np.resize(io.imread(url), (299, 299,3)).astype(float)\n",
    "    print(image.shape)\n",
    "    # our input image is now represented as a NumPy array of shape\n",
    "    # (inputShape[0], inputShape[1], 3) however we need to expand the\n",
    "    # dimension by making the shape (1, inputShape[0], inputShape[1], 3)\n",
    "    # so we can pass it through thenetwork\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # pre-process the image using the appropriate function based on the\n",
    "    # model that has been loaded (i.e., mean subtraction, scaling, etc.)\n",
    "    image = preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "base_model = Xception(weights='imagenet',input_shape=(299, 299, 3))\n",
    "image_model = Model(inputs=base_model.input, outputs=base_model.get_layer('avg_pool').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "# image_file_name = 'http://www.newarkhistory.com/indparksoccerkids.jpg'\n",
    "# image = io.imread(image_file_name)\n",
    "\n",
    "image_preprocessed = image_preprocess(\"http://www.newarkhistory.com/indparksoccerkids.jpg\")\n",
    "features = image_model.predict(image_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "question_vector = get_ques_vector('what sport are they playing?')\n",
    "pred = model.predict([features, question_vector])[0]\n",
    "top_pred = pred.argsort()[-5:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Soccer', 34.189999999999998)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(metadata['ix_to_ans'][str(_)].title(), round(pred[_]*100.0,2)) for _ in top_pred][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
